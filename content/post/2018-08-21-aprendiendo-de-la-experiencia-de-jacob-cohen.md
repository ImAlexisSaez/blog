---
title:  "Aprendiendo de la experiencia de Jacob Cohen"
slug:   "aprendiendo-de-la-experiencia-de-jacob-cohen"
date:   "2018-08-21T05:59:39+02:00"
draft:  false
bigimg: [{src: "img/blog/20180821-cabecera.jpg"}]
apartados: ["Blog"]
etiquetas: ["Estadística"]
---

Por recomendación, el otro día puse las manos sobre el artículo de *Jacob Cohen*: "*Things I Have Learned (So Far)*", publicado originalmente en diciembre de 1990 en la revista *American Psychologist*. Veamos qué impresiones me ha dejado su lectura.
<!--more-->

Es posible que, por su antigüedad, alguien pueda llegar a pensar que no merece demasiado la pena dedicarle tiempo a este texto, ¡nada más lejos de la realidad!

El acceso al documento original ([enlace](http://psycnet.apa.org/psycinfo/1991-11596-001)), desgraciadamente, implica un desembolso de aproximadamente doce dólares. No obstante, a través de una búsqueda rápida en *Google* es fácil (y, posiblemente, ilegal) dar con él e, incluso, con una traducción al español, publicada en el año 1992 en la revista *Anales de Psicología*. La pregunta natural aquí es, ¿por qué un artículo publicado hace más de dos décadas no ha sido liberado completamente?

Algunas de las claves que comparte Jacob Cohen y me han parecido interesantes son:

- En la medida de nuestras posibilidades, debemos evitar el uso inconsciente de las famosas "*reglas de oro*", que suelen instaurar rígidos criterios universales. Por ejemplo, en lugar de calificar una muestra como pequeña porque su tamaño es menor que treinta, conviene que llevemos a cabo un análisis del poder estadístico del estudio, para decidir si el tamaño muestral es el idóneo para los objetivos que perseguimos.
- "*Menos es más*" (salvo cuando hablamos de tamaños muestrales). No es demasiado recomendable que nuestros proyectos se caractericen por tener un número desproporcionado de variables dependientes, o independientes, o de ambos tipos. En esos casos, la cantidad de hipótesis a contrastar crece desmesuradamente, y deberíamos estar muy atentos al control del *error de tipo I*.
- En relación con lo anterior, es aconsejable que prestemos atención también a la forma de presentar resultados. Los programas informáticos de hoy en día son capaces de arrojar cifras con un alto número de decimales, pero debemos detenernos a pensar hasta qué punto es útil reportarlos todos.
- "*Simple es mejor*". Conviene que describamos gráficamente una variable antes que optar por hacerlo vía sus primeros momentos, así como que utilicemos un diagrama de puntos en lugar de escoger un indicador numérico para transmitir en qué medida están asociadas dos variables.
- Que podamos realizar, de manera sencilla, complejos análisis de datos utilizando programas informáticos, no implica que no sea necesario entender perfectamente qué estamos haciendo en cada momento del proceso.
- Conviene que nos detengamos a estudiar con detalle todo lo relacionado con la correcta interpretación del *p*-valor ("*this result does not tell us about the truth of the null hypothesis, given the data […] What it tells us is the probability of the data, given the truth of the null hypothesis.*").
- Continuando con el punto anterior, no tenemos que utilizar el *p*-valor como sustituto de un indicador del tamaño del efecto, y es recomendable que reportemos un intervalo de confianza de este último (de hecho, debería ser el principal objetivo de cualquier investigación) en la sección de resultados, para que los hallazgos significativos queden correctamente contextualizados.
- Conviene, antes de llevar a cabo cualquier estudio, que planeemos con atención el tamaño del efecto que buscamos, el nivel de significación que vamos a asumir y el poder estadístico con el que queremos trabajar. A partir de ellos, obtendremos el tamaño muestral necesario y, en el caso de encontrarse éste fuera de nuestras posibilidades, procederemos a realizar ajustes en las anteriores cantidades.

Por otra parte, algunas de las citas que me han encantado del artículo son:

> "I have so heavily emphasized the desirability of working with few variables and large sample sizes that some of my students have spread the rumor that my idea of the perfect study is one with 10,000 cases and no variables. They go too far."

> "We sometimes learn more from what we see than from what we compute; sometimes what we learn from what we see is that we shouldn’t compute, at least not on those data as they stand."

> "The atmosphere that characterizes statistics as applied in the social and biomedical sciences is that of a secular religion (Salsburg, 1985), apparently of Judeo-Christian derivation, as it employs as its most powerful icon a six-pointed cross, often presented multiply for enhanced authority. I confess that I am an agnostic."

> "Despite widespread misconceptions to the contrary, the rejection of a given null hypothesis gives us no basis for estimating the probability that a replication of the research will again result in rejecting that null hypothesis."

> "consider the sanctified (and sanctifying) magic .05 level. […] Its arbitrary unreasonable tyranny has led to data fudging of varying degrees of subtlety from grossly altering data to dropping cases where there 'must have been' errors."

> "I have learned and taught that the primary product of a research inquiry is one or more measures of effect size, not *p* values."

En resumen, una amena lectura aderezada de píldoras de sabiduría que recomendaría a cualquier persona interesada en esta disciplina.

*P. S. (acerca de la imagen de cabecera):* anhelo tranquilidad, como aquella que debe disfrutarse en un lugar como el que aparece la fotografía de [Riccardo Chiarini](https://unsplash.com/@riccardoch), disponible en [Unsplash](https://unsplash.com/photos/p7huyfLrdzc).